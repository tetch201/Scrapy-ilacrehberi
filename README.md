# crawler-Scrapy
Crawler для парсинга фармацевтического сайта ilacrehberi.com
# Особенности:
1. Встроенная функция State для остановки/запуска с точки прошлой остановки парсера
2. Запись данных порционально для защиты от вылетов и потери словаря с данными (запись после каждой итерации нецелессообразна из-за значительного снижения скорости парсинга)
3. Парсер ведет лог
4. Беспорядочная структура сайта идеально демонстрирует преимущество crawlSpider для парсинга данного ресурса. (Парсер сам проваливается во все найденные ссылки, и ведет запись только нужных данных, исходя из своих настроек)
# Запуск
```bash
git clone https://github.com/tetch201/crawler-Scrapy
cd crawl/spiders
scrapy crawl ilacrehberi
```
# Фреймворк и инструменты:
```bash
pip install Scrapy
pip install pandas
pip install fake-useragent
```
# p.s.
Если не хотите устанавливать зависимости глобально, рекомендуется создать виртуальное окружение после копирования репозитория.
